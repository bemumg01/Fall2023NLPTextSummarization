{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcec0bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import re\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from nltk.lm import MLE   # N-Gram Model\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline   # Preprocessing for N-Gram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0b9bf78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>genres</th>\n",
       "      <th>summary</th>\n",
       "      <th>link</th>\n",
       "      <th>is_novel</th>\n",
       "      <th>sum_len</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>986</td>\n",
       "      <td>The Plague</td>\n",
       "      <td>Albert Camus</td>\n",
       "      <td>1947</td>\n",
       "      <td>novel</td>\n",
       "      <td>The text of The Plague is divided into five p...</td>\n",
       "      <td>https://www.gutenberg.org/files/30062/30062.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>1120</td>\n",
       "      <td>30062_30062.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6921</td>\n",
       "      <td>Carmilla</td>\n",
       "      <td>Sheridan Le Fanu</td>\n",
       "      <td>1872</td>\n",
       "      <td>fiction</td>\n",
       "      <td>The story is presented by Le Fanu as part of ...</td>\n",
       "      <td>https://www.gutenberg.org/files/10007/10007-0.txt</td>\n",
       "      <td>False</td>\n",
       "      <td>934</td>\n",
       "      <td>10007_10007-0.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7923</td>\n",
       "      <td>Dracula</td>\n",
       "      <td>Bram Stoker</td>\n",
       "      <td>1897</td>\n",
       "      <td>horror</td>\n",
       "      <td>The novel is told in epistolary format, as a ...</td>\n",
       "      <td>https://www.gutenberg.org/files/345/345-0.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>986</td>\n",
       "      <td>345_345-0.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7923</td>\n",
       "      <td>Dracula</td>\n",
       "      <td>Bram Stoker</td>\n",
       "      <td>1897</td>\n",
       "      <td>horror</td>\n",
       "      <td>The novel is told in epistolary format, as a ...</td>\n",
       "      <td>https://www.gutenberg.org/files/45839/45839-0.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>986</td>\n",
       "      <td>45839_45839-0.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>8237</td>\n",
       "      <td>Don Quixote</td>\n",
       "      <td>Miguel de Cervantes</td>\n",
       "      <td>1605</td>\n",
       "      <td>novel</td>\n",
       "      <td>The First Sally Alonso Quijano, the protagoni...</td>\n",
       "      <td>https://www.gutenberg.org/files/996/996-0.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>1592</td>\n",
       "      <td>996_996-0.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    id        title               author pub_date   genres  \\\n",
       "0           0   986   The Plague         Albert Camus     1947    novel   \n",
       "1           2  6921     Carmilla     Sheridan Le Fanu     1872  fiction   \n",
       "2           3  7923      Dracula          Bram Stoker     1897   horror   \n",
       "3           4  7923      Dracula          Bram Stoker     1897   horror   \n",
       "4           5  8237  Don Quixote  Miguel de Cervantes     1605    novel   \n",
       "\n",
       "                                             summary  \\\n",
       "0   The text of The Plague is divided into five p...   \n",
       "1   The story is presented by Le Fanu as part of ...   \n",
       "2   The novel is told in epistolary format, as a ...   \n",
       "3   The novel is told in epistolary format, as a ...   \n",
       "4   The First Sally Alonso Quijano, the protagoni...   \n",
       "\n",
       "                                                link  is_novel  sum_len  \\\n",
       "0    https://www.gutenberg.org/files/30062/30062.txt      True     1120   \n",
       "1  https://www.gutenberg.org/files/10007/10007-0.txt     False      934   \n",
       "2      https://www.gutenberg.org/files/345/345-0.txt      True      986   \n",
       "3  https://www.gutenberg.org/files/45839/45839-0.txt      True      986   \n",
       "4      https://www.gutenberg.org/files/996/996-0.txt      True     1592   \n",
       "\n",
       "           file_name  \n",
       "0    30062_30062.txt  \n",
       "1  10007_10007-0.txt  \n",
       "2      345_345-0.txt  \n",
       "3  45839_45839-0.txt  \n",
       "4      996_996-0.txt  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_df = pd.read_csv(\"/home/x-mbemus/Desktop/cleaner_summaries.csv\")   # Import summary document.\n",
    "sum_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f651414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.gutenberg.org/files/10007/10007-0.txt\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "start_token = \"*** START OF THIS PROJECT GUTENBERG EBOOK\"   # Theoretical divider for start of texts.\n",
    "\n",
    "end_token = \"*** END OF THIS PROJECT GUTENBERG EBOOK\"   # Theoretical divider for end of texts.\n",
    "\n",
    "print(sum_df.at[1, \"link\"])   # Sample entry.\n",
    "\n",
    "f = open(\"/home/x-mbemus/Desktop/text_files/\" + sum_df.at[1, \"file_name\"], \"r\")   # Opening file.\n",
    "\n",
    "j = 0   # Iterable\n",
    "\n",
    "for i in f:    # Iterate through file.\n",
    "    if j == 22:   # Find line 22.\n",
    "        x = str(i)[2:-5]   # Capture start of line.\n",
    "        print(x[0:len(start_token)] == start_token)   # Compare to start_token.\n",
    "    j += 1   # Increase iterable.\n",
    "\n",
    "# More testing for start tokens.\n",
    "#for i in f:\n",
    "#    try:\n",
    "#        x = re.sub(\"\\\\n\", \"\", i.decode(\"utf-8\"))\n",
    "    \n",
    "        #if actv == True:\n",
    "        \n",
    "        #if x.strip() != \"\":\n",
    "#        print(x)\n",
    "    \n",
    "        #if x[0:len(start_token)] == start_token:\n",
    "            #actv == True\n",
    "#    except:\n",
    "#        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de66fa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempting to better identify last sentences.\n",
    "\n",
    "f = open(\"/home/x-mbemus/Desktop/text_files/\" + sum_df.at[0, \"file_name\"], \"r\")   # Open first text.\n",
    "\n",
    "# Theoretical start and end tokens.\n",
    "start_token = \"*** START OF THIS PROJECT GUTENBERG EBOOK\"\n",
    "\n",
    "end_token = \"*** END OF THIS PROJECT GUTENBERG EBOOK\"\n",
    "\n",
    "actv = False   # Will be active when copying begins.\n",
    "\n",
    "y = \"\"   # Empty string.\n",
    "for i in f:   # Iterate through text.\n",
    "    x = str(i)[2:-5]   # Select first line.\n",
    "    x = re.sub(\"_+\", \"\", x)   # Remove underscores.\n",
    "    x = re.sub(\"\\s+\", \" \", x)   # Remove extra whitespace.\n",
    "    \n",
    "    if x[0:len(end_token)] == end_token:   # Check if it's the end token. \n",
    "        actv = False   # Stop copying.\n",
    "    \n",
    "    if actv == True and x != \"\":   # If line isn't empty and copying is active.\n",
    "        line = x.split(\" \")   # Break the line into space-separated tokens.\n",
    "        for j in line:   # For each toekn.\n",
    "            if re.search(\"[\\.\\?!]\", j) == None:   # If there's no punctuation.\n",
    "                y += j + \" \"   # Add a space after it. \n",
    "            else:   # If there is puncuation.\n",
    "                y += j    # No space.\n",
    "                if re.search(\"^[0-9\\.]\", y) == None:   # If it starts with numbers or a period.\n",
    "                    print(y.strip())   # Print.\n",
    "                y = \"\"    # Start a new line.\n",
    "                \n",
    "        \n",
    "    if x[0:len(start_token)] == start_token:    # If we match start token.\n",
    "        actv = True   # Start copying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73012549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_index = list(sum_df.sample(frac=.2).index)\n",
    "\n",
    "#train_index = []   # Need to pick all indecies not in test set.\n",
    "#for i in sum_df.index:   # A for loop is probably not the fastest way of doing this, but it works.\n",
    "#    if i not in test_index:\n",
    "#        train_index.append(i)\n",
    "\n",
    "#train_df = sum_df.loc[train_index][:]   # Create train set.\n",
    "#test_df = sum_df.loc[test_index][:]   # Create test set.\n",
    "\n",
    "#train_df.reset_index(inplace = True, drop=True)\n",
    "#test_df.reset_index(inplace = True, drop=True)\n",
    "\n",
    "#train_df.to_csv(\"/home/x-mbemus/Desktop/text_train_data.csv\", index=False)\n",
    "#test_df.to_csv(\"/home/x-mbemus/Desktop/text_test_data.csv\", index=False)\n",
    "\n",
    "# Reading in files.\n",
    "train_df = pd.read_csv(\"/home/x-mbemus/Desktop/text_train_data.csv\")\n",
    "test_df = pd.read_csv(\"/home/x-mbemus/Desktop/text_test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8579a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://clementbm.github.io/theory/2021/12/23/rouge-bleu-scores.html\n",
    "#!pip install sacrebleu\n",
    "#!pip install rouge\n",
    "\n",
    "# Importing metrics.\n",
    "from sacrebleu.metrics import BLEU\n",
    "bleu_scorer = BLEU(effective_order=True)\n",
    "\n",
    "from rouge import Rouge\n",
    "rouge_scorer = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36421ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605\n"
     ]
    }
   ],
   "source": [
    "# Checking for average summary length.\n",
    "sum_len = []   # List to contain lengths.\n",
    "for i in train_df.loc[:][\"summary\"]:   # For each summary.\n",
    "    sum_len.append(len(i.split(\" \")))   # Count space-separated tokens.\n",
    "sent_gen = round(np.mean(sum_len))   # take mean of all summaries.\n",
    "print(sent_gen)   # print mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052b12b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648/666\n"
     ]
    }
   ],
   "source": [
    "# Start getting results for training.\n",
    "# Dict to store results.\n",
    "results = {\"title\":[], \"target\":[], \"pred\":[], \"BLEU\":[], \"ROUGE\":[]}\n",
    "\n",
    "exceptions = []   # List to hold any problems we run into.\n",
    "\n",
    "for h in train_df.index:   # Begin iterating.\n",
    "    try:\n",
    "        actv = False   # Start without copying.\n",
    "\n",
    "        f = open(\"/home/x-mbemus/Desktop/text_files/\" + sum_df.at[h, \"file_name\"], \"r\")   # Open file.\n",
    "    \n",
    "        data = []   # Store sentences here.\n",
    "        y = []    # Store words here.\n",
    "    \n",
    "        for i in f:   # Iterate through file.\n",
    "            # Text preprocessing for every line.\n",
    "            x = re.sub(\"_+\", \"\", i)   # Remove underscores.\n",
    "            x = re.sub(\"\\s+\", \" \", x)   # Remove extra spaces.\n",
    "            x = re.sub(\"\\\\n\", \"\", x)   # Remove linebreaks.\n",
    "\n",
    "            if x != \"\":    # If x isn't empty.\n",
    "                line = x.split(\" \")   # Collect space-separated tokens.\n",
    "                for j in line:   # For each token.\n",
    "                    y.append(j)   # Add to list.\n",
    "                    if re.search(\"[\\.\\?!]\", j) != None:   # If we find punctuation.\n",
    "                        data.append(y)   # Add sentence to sentence list.\n",
    "                        y = []   # Start new sentence.\n",
    "            \n",
    "        target = train_df.at[h, \"summary\"]   # Extract target summary.\n",
    "        \n",
    "        for k in [1, 2, 3, 4, 5]:   # Testing each n-gram in given list.\n",
    "        \n",
    "            train_data, vocab = padded_everygram_pipeline(k, data)   # Process sentence list.\n",
    "        \n",
    "            ngram = MLE(k)   # Assign model.\n",
    "            ngram.fit(train_data, vocab)   # Fit model.\n",
    "        \n",
    "            output = ngram.generate(sent_gen, random_seed=42)   # Generate mean number of characters.\n",
    "        \n",
    "            full_output = \"\"   # String to store output.\n",
    "    \n",
    "            for i in output:   # For token in output.\n",
    "                if re.search(\"</?s>\", i) == None:   # If not a start/stop token.\n",
    "                    full_output += i + \" \"   # Add to sentence.\n",
    "        \n",
    "            full_output = full_output.strip()   # Remove extra spaces.\n",
    "        \n",
    "            # Score on metrics.\n",
    "            blue = bleu_scorer.sentence_score(hypothesis=full_output, references=[target])\n",
    "            red = rouge_scorer.get_scores(hyps=full_output, refs=target)\n",
    "        \n",
    "            # Add results to dictionary.\n",
    "            results[\"title\"].append(train_df.at[h, \"title\"])\n",
    "            results[\"target\"].append(target)\n",
    "            results[\"n\"].append(k)\n",
    "            results[\"pred\"].append(full_output)\n",
    "            results[\"BLEU\"].append(blue.score)\n",
    "            results[\"ROUGE\"].append(red[0][\"rouge-l\"][\"f\"])\n",
    "    \n",
    "    except Exception as e:   # Report any issues.\n",
    "        exceptions.append((h, e))\n",
    "    \n",
    "    # Track process.\n",
    "    clear_output(wait=True)\n",
    "    print(f'{h+1}/{len(train_df.index)}')\n",
    "\n",
    "train_results = pd.DataFrame(results)   # Convert dictionary to data frame.\n",
    "train_results.to_csv(\"/home/x-mbemus/Desktop/NGRAM_train_result.csv\", index=False)   # Save file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24e140d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exceptions)   # Count exceptions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef125cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4578767076863248\n",
      "0.1172296911575709\n",
      "0.6168586452479008\n",
      "0.11836204904804738\n",
      "0.08115851441234766\n",
      "0.02952460613606504\n",
      "0.08804820281626032\n",
      "0.02958704111494906\n",
      "0.06209394881221388\n",
      "0.029053551100357036\n"
     ]
    }
   ],
   "source": [
    "for i in [1, 2, 3, 4, 5]:   # Check results.\n",
    "    print(np.mean(train_results.loc[train_results[\"n\"] == i][\"BLEU\"]))\n",
    "    print(np.mean(train_results.loc[train_results[\"n\"] == i][\"ROUGE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f25e0066-cac2-45c9-a440-90b9e372f2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['flagged'] = 0   # If we had any exceptions, flag it.\n",
    "for i in exceptions:\n",
    "    train_df.at[i[0], \"flagged\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "891b0b10-95e9-4451-9dc0-7d4b55107067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>genres</th>\n",
       "      <th>summary</th>\n",
       "      <th>link</th>\n",
       "      <th>is_novel</th>\n",
       "      <th>sum_len</th>\n",
       "      <th>file_name</th>\n",
       "      <th>flagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>6921</td>\n",
       "      <td>Carmilla</td>\n",
       "      <td>Sheridan Le Fanu</td>\n",
       "      <td>1872</td>\n",
       "      <td>fiction</td>\n",
       "      <td>The story is presented by Le Fanu as part of ...</td>\n",
       "      <td>https://www.gutenberg.org/files/10007/10007-0.txt</td>\n",
       "      <td>False</td>\n",
       "      <td>934</td>\n",
       "      <td>10007_10007-0.txt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>7923</td>\n",
       "      <td>Dracula</td>\n",
       "      <td>Bram Stoker</td>\n",
       "      <td>1897</td>\n",
       "      <td>horror</td>\n",
       "      <td>The novel is told in epistolary format, as a ...</td>\n",
       "      <td>https://www.gutenberg.org/files/345/345-0.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>986</td>\n",
       "      <td>345_345-0.txt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>7923</td>\n",
       "      <td>Dracula</td>\n",
       "      <td>Bram Stoker</td>\n",
       "      <td>1897</td>\n",
       "      <td>horror</td>\n",
       "      <td>The novel is told in epistolary format, as a ...</td>\n",
       "      <td>https://www.gutenberg.org/files/45839/45839-0.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>986</td>\n",
       "      <td>45839_45839-0.txt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>8237</td>\n",
       "      <td>Don Quixote</td>\n",
       "      <td>Miguel de Cervantes</td>\n",
       "      <td>1605</td>\n",
       "      <td>novel</td>\n",
       "      <td>The First Sally Alonso Quijano, the protagoni...</td>\n",
       "      <td>https://www.gutenberg.org/files/996/996-0.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>1592</td>\n",
       "      <td>996_996-0.txt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>13535</td>\n",
       "      <td>Heart of Darkness</td>\n",
       "      <td>Joseph Conrad</td>\n",
       "      <td>1899</td>\n",
       "      <td>novel</td>\n",
       "      <td>'Heart of Darkness' opens in first person nar...</td>\n",
       "      <td>https://www.gutenberg.org/files/219/219-0.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>3127</td>\n",
       "      <td>219_219-0.txt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id              title               author pub_date  \\\n",
       "0           2   6921           Carmilla     Sheridan Le Fanu     1872   \n",
       "1           3   7923            Dracula          Bram Stoker     1897   \n",
       "2           4   7923            Dracula          Bram Stoker     1897   \n",
       "3           5   8237        Don Quixote  Miguel de Cervantes     1605   \n",
       "4           9  13535  Heart of Darkness        Joseph Conrad     1899   \n",
       "\n",
       "    genres                                            summary  \\\n",
       "0  fiction   The story is presented by Le Fanu as part of ...   \n",
       "1   horror   The novel is told in epistolary format, as a ...   \n",
       "2   horror   The novel is told in epistolary format, as a ...   \n",
       "3    novel   The First Sally Alonso Quijano, the protagoni...   \n",
       "4    novel   'Heart of Darkness' opens in first person nar...   \n",
       "\n",
       "                                                link  is_novel  sum_len  \\\n",
       "0  https://www.gutenberg.org/files/10007/10007-0.txt     False      934   \n",
       "1      https://www.gutenberg.org/files/345/345-0.txt      True      986   \n",
       "2  https://www.gutenberg.org/files/45839/45839-0.txt      True      986   \n",
       "3      https://www.gutenberg.org/files/996/996-0.txt      True     1592   \n",
       "4      https://www.gutenberg.org/files/219/219-0.txt      True     3127   \n",
       "\n",
       "           file_name  flagged  \n",
       "0  10007_10007-0.txt        0  \n",
       "1      345_345-0.txt        0  \n",
       "2  45839_45839-0.txt        0  \n",
       "3      996_996-0.txt        0  \n",
       "4      219_219-0.txt        0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d8d7bda-4f04-4b05-a23d-c027db1e849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"/home/x-mbemus/Desktop/text_test_data2.csv\")   # Save new train flagged data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f1d441c-7d89-47d2-b1ed-1c7ef643a53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2303742/1252738319.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{h+1}/{len(test_df.index)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mtest_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0mttest_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/x-mbemus/Desktop/NGRAM_test_result.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/anvil/external/apps/jupyter/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/anvil/external/apps/jupyter/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m     return arrays_to_mgr(\n\u001b[0m\u001b[1;32m    465\u001b[0m         \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     )\n",
      "\u001b[0;32m/apps/anvil/external/apps/jupyter/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/anvil/external/apps/jupyter/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All arrays must be of the same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "# Now start testing.\n",
    "# Dictionary to store results.\n",
    "results = {\"title\":[], \"target\":[], \"n\":[], \"pred\":[], \"BLEU\":[], \"ROUGE\":[]}\n",
    "\n",
    "exceptions = []   # List of exceptions.\n",
    "\n",
    "for h in test_df.index:   # Iterate through test observations.\n",
    "    try:\n",
    "        actv = False    # Don't copy text.\n",
    "        \n",
    "        # Open file.\n",
    "        f = open(\"/home/x-mbemus/Desktop/text_files/\" + test_df.at[h, \"file_name\"], \"r\")\n",
    "    \n",
    "        # Store sentences and words.\n",
    "        data = []\n",
    "        y = []\n",
    "        \n",
    "        for i in f:   # Iterate through words.\n",
    "            # Preprocess.\n",
    "            x = re.sub(\"_+\", \"\", i)\n",
    "            x = re.sub(\"\\s+\", \" \", x)\n",
    "            x = re.sub(\"\\\\n\", \"\", x)\n",
    "\n",
    "            if x != \"\":   # Split lines into tokens.\n",
    "                line = x.split(\" \")\n",
    "                for j in line:\n",
    "                    y.append(j)   # Add token to sentence.\n",
    "                    if re.search(\"[\\.\\?!]\", j) != None:   # If punctuation.\n",
    "                        data.append(y)   # Add sentence to sentence list.\n",
    "                        y = []    # Start new sentence.\n",
    "            \n",
    "        target = test_df.at[h, \"summary\"]   # Open target.\n",
    "        \n",
    "        # Format data.\n",
    "        train_data, vocab = padded_everygram_pipeline(2, data)\n",
    "        \n",
    "        # Create model.\n",
    "        ngram = MLE(2)\n",
    "        ngram.fit(train_data, vocab)\n",
    "        \n",
    "        # Generate new summary.\n",
    "        output = ngram.generate(605, random_seed=42)\n",
    "        \n",
    "        full_output = \"\"   # String for storage.\n",
    "    \n",
    "        for i in output:   # For each output word\n",
    "            if re.search(\"</?s>\", i) == None:   # If not start or stop token.\n",
    "                full_output += i + \" \"   # Add to list with space.\n",
    "        \n",
    "        full_output = full_output.strip()   # Remove extra spaces.\n",
    "        \n",
    "        # Compute metrics.\n",
    "        blue = bleu_scorer.sentence_score(hypothesis=full_output, references=[target])\n",
    "        red = rouge_scorer.get_scores(hyps=full_output, refs=target)\n",
    "        \n",
    "        # Add results to dictionary.\n",
    "        results[\"title\"].append(test_df.at[h, \"title\"])\n",
    "        results[\"target\"].append(target)\n",
    "        results[\"pred\"].append(full_output)\n",
    "        results[\"BLEU\"].append(blue.score)\n",
    "        results[\"ROUGE\"].append(red[0][\"rouge-l\"][\"f\"])\n",
    "    \n",
    "        # Observation does not need flag.\n",
    "        test_df.at[h, \"flagged\"] = 0\n",
    "        \n",
    "    except Exception as e:\n",
    "        exceptions.append((h, e))   # Add exception to exceptions list.\n",
    "        test_df.at[h, \"flagged\"] = 1   # Flag observation.\n",
    "    \n",
    "    # Output current status.\n",
    "    clear_output(wait=True)\n",
    "    print(f'{h+1}/{len(test_df.index)}')\n",
    "\n",
    "# Convert to dataframe and save.\n",
    "test_results = pd.DataFrame(results)\n",
    "ttest_results.to_csv(\"/home/x-mbemus/Desktop/NGRAM_test_result.csv\", index=False)\n",
    "\n",
    "# Error is caused because I accidentally left \"n\" in dictionary and forgot to fill it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e912b05a-448e-4e2c-8f4c-d10c331bbcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix mistake causing error above.\n",
    "result2 = {}   # New result dictionary.\n",
    "for i in [\"title\", \"target\", \"pred\", \"BLEU\", \"ROUGE\"]:   # For desired keys.\n",
    "    result2[i] = results[i]   # Add those results to new dictionary.\n",
    "test_results = pd.DataFrame(result2)   # Create new data frame.\n",
    "test_results.to_csv(\"/home/x-mbemus/Desktop/NGRAM_test_result.csv\", index=False)   # Save dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ed1f9fe-9219-4277-a09f-1643d79a270c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8010884307295432\n",
      "0.13885795183534103\n"
     ]
    }
   ],
   "source": [
    "# Checking current results.\n",
    "print(np.mean(test_results.loc[:][\"BLEU\"]))\n",
    "print(np.mean(test_results.loc[:][\"ROUGE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c83ee971-77b9-404d-8f5a-1985b8397c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"/home/x-mbemus/Desktop/text_test_dataf.csv\", index=False)    # Save flagged test file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42c644b9-4c92-4648-a211-50c586d3ca85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666\n"
     ]
    }
   ],
   "source": [
    "# More flag testing.\n",
    "for i in train_df.index:\n",
    "    try:\n",
    "        f = open(\"/home/x-mbemus/Desktop/text_files/\" + train_df.at[i, \"file_name\"], \"r\")\n",
    "        x = f.readlines()\n",
    "        train_df.at[i, \"flagged\"] = 0\n",
    "    except:\n",
    "        train_df.at[i, \"flagged\"] = 1\n",
    "    \n",
    "    clear_output(wait=True)    \n",
    "    print(f'{i+1}/{len(train_df.index)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "815d8952-6fdf-4c6c-964d-1e03385db327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df.index[train_df['flagged'] == 1])   # Check number flagged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8e277cd-45aa-4a88-bfa7-28605cf4fc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "738.4\n",
      "568.6\n",
      "-169.8\n"
     ]
    }
   ],
   "source": [
    "# Open test result file.\n",
    "test_out = pd.read_csv(\"/home/x-mbemus/Desktop/NGRAM_test_result.csv\")\n",
    "\n",
    "# Add some new metrics to measure.\n",
    "for i in test_out.index:\n",
    "    test_out.at[i, \"targ_len\"] = len(test_out.at[i, \"target\"].split(\" \"))\n",
    "    test_out.at[i, \"pred_len\"] = len(test_out.at[i, \"pred\"].split(\" \"))\n",
    "    test_out.at[i, \"len_diff\"] = test_out.at[i, \"pred_len\"] - test_out.at[i, \"targ_len\"]\n",
    "\n",
    "# Print average of those.\n",
    "print(np.mean(test_out.loc[:]['targ_len']))\n",
    "print(np.mean(test_out.loc[:]['pred_len']))\n",
    "print(np.mean(test_out.loc[:]['len_diff']))\n",
    "\n",
    "# \"title\", \"target\", \"pred\", \"BLEU\", \"ROUGE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05fb1ed-a0c8-46dc-837a-a89a8b126c19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (Anaconda 2021.05)",
   "language": "python",
   "name": "anaconda-2021.05-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
