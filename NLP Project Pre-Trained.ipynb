{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82c7e570-78af-4bb4-9bf9-985f38bbd966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy==1.22.1 in /home/x-mbemus/.local/lib/python3.8/site-packages (1.22.1)\n",
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.22.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52a3343b-039b-4a47-a2f4-86e81ba38d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "931dd9f5-c5a3-4e2c-ae30-217a36e58f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmichael-bemus\u001b[0m (\u001b[33mmichael-bemus01\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()   # Log into wandb to track computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a388963-4237-488a-8b99-17500b785c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2adf827-2e8c-494e-8b87-9b3f237367c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacrebleu.metrics import BLEU\n",
    "bleu_scorer = BLEU(effective_order=True)\n",
    "\n",
    "from rouge import Rouge\n",
    "rouge_scorer = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c6ef8b2-9e1e-472f-bbd1-9754db04afc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/x-mbemus/Desktop/text_train_data.csv\")   # Read in trainign df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "504ea250-5e02-42ac-b107-63ed82e6461c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31, 66, 83]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "And we need to find five later.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "But not yet.\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/4664850/how-to-find-all-occurrences-of-a-substring\n",
    "\n",
    "# Code to find linebreaks in text.\n",
    "# Sample string.\n",
    "samp_string = \"We need to identify 4 of these.\\n\\n\\n\\nAnd we need to find five later.\\n\\n\\n\\n\\nBut not yet.\\n\\n\\n\\n\\nNow.\"\n",
    "chunks = [m.start() for m in re.finditer('\\n\\s*\\n\\s*\\n\\s*\\n', samp_string)]   # Extract all occurences of string.\n",
    "print(chunks)   # Pring chunks.\n",
    "samp_string = samp_string[:chunks[-1]]   # Remove all after last.\n",
    "samp_string = samp_string[chunks[0]:]   # Remove all before first.\n",
    "print(samp_string)    # Print new text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "781fa251-3aa3-481b-b444-9be52acda693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[933, 996, 1086, 1419, 35212, 59430, 92793, 124165, 148347, 171760, 222362, 248457]\n"
     ]
    }
   ],
   "source": [
    "f = open(\"/home/x-mbemus/Desktop/text_files/\" + df.at[61, \"file_name\"])   # Open random file.\n",
    "text = ' '.join(f.readlines())   # Read in file.\n",
    "chunks = [m.start() for m in re.finditer('\\n\\s*\\n\\s*\\n', text)]   # Find string occurences.\n",
    "print(chunks)   # Print occurences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70ffa602-f308-42d5-be69-2e719cecab88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Index: 665/665\n"
     ]
    }
   ],
   "source": [
    "for i in df.index:   # For each text.\n",
    "    # Track progress.\n",
    "    clear_output(wait=True)\n",
    "    print(f\"Current Index: {i}/{len(df.index)-1}\")\n",
    "    try:\n",
    "        # Open file.\n",
    "        f = open(\"/home/x-mbemus/Desktop/text_files/\" + df.at[i, \"file_name\"], \"r\", errors=\"ignore\")\n",
    "        text = ' '.join(f.readlines())   # Read in text.\n",
    "    except:\n",
    "        text = \"\\n \\n \\n \\n \\n \\n \\n\"\n",
    "    # Find triple linebreaks.\n",
    "    chunks = [ind.start() for ind in re.finditer('\\n\\s*\\n\\s*\\n', text)]\n",
    "    text = text[:chunks[-1]]   # Remove everything after last triple-linebreak.\n",
    "    text = text[chunks[0]:]   # Remove everything before first.\n",
    "    text = re.sub(r\"\\\\n|\\\\t\", \" \", text)   # Remove linebreaks and tabs..\n",
    "    text = re.sub(r\"\\s+\", \" \", text)   # Remove extra spaces. \n",
    "    df.at[i, \"full_text\"] = text   # Save as full_text in df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e0db7e5-064f-4f4d-bba1-4d3ad207dfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest Text: 566193\n",
      "Longest Document: War and Peace\n",
      "Smallest Text: 1\n",
      "Shortest Document: Alaska\n"
     ]
    }
   ],
   "source": [
    "# Find min and max text lengths.\n",
    "min_text = 999999999   # Start min.\n",
    "max_text = 0   # Start max.\n",
    "for i in df.index:   # For each text.\n",
    "    t_len = len(df.at[i, \"full_text\"].split(\" \"))   # Read in tokens and count.\n",
    "    if t_len > max_text:   # If longer than current max,\n",
    "        max_text = t_len   # Assign as max.\n",
    "        max_ind = i   # Save index.\n",
    "    if t_len < min_text:   # If smaller than current min,\n",
    "        min_text = t_len   # Assign as min.\n",
    "        min_ind = i   # Save index.\n",
    "\n",
    "# Print results. \n",
    "print(f\"Longest Text: {max_text}\\nLongest Document: {df.at[max_ind, 'title']}\")\n",
    "print(f\"Smallest Text: {min_text}\\nShortest Document: {df.at[min_ind, 'title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "addc10c4-607d-49df-8ec8-3f468a636218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest Summary: 5475\n",
      "\tDocument: The Scapegoat\n",
      "Smallest Summary: 4\n",
      "\tDocument: The American Claimant\n"
     ]
    }
   ],
   "source": [
    "# Repeat above process for summaries. \n",
    "smlst = 999999999\n",
    "bigst = 0\n",
    "for i in df.index:\n",
    "    text = re.sub(r\"\\\\n|\\\\t\", \" \", df.at[i, 'summary'])\n",
    "    t_len = len(text.split(\" \"))\n",
    "    if t_len > bigst:\n",
    "        bigst = t_len\n",
    "        big_ind = i\n",
    "    if t_len < smlst:\n",
    "        smlst = t_len\n",
    "        sml_ind = i\n",
    "print(f\"Longest Summary: {bigst}\\n\\tDocument: {df.at[big_ind, 'title']}\")\n",
    "print(f\"Smallest Summary: {smlst}\\n\\tDocument: {df.at[sml_ind, 'title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc308c74-207f-41e0-898e-0aef985f7387",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df   # Remove training df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2fd87aa-1765-4dea-ba63-d89d37f062c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/x-mbemus/Desktop/text_test_dataf.csv\")   # Read in test dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef811ad6-61c3-49c8-b2ee-c1bb9ac484c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# Show effect of removing flagged observations.\n",
    "print(len(df.index))\n",
    "print(len(df[df[\"flagged\"] == 0].index))\n",
    "\n",
    "# Remove flagged observations..\n",
    "df = df[df[\"flagged\"] == 0].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac944a93-cf0d-47ab-ac41-62ae41cad707",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.index:   # Read in text files.\n",
    "    # Open file.\n",
    "    f = open(\"/home/x-mbemus/Desktop/text_files/\" + df.at[i, \"file_name\"], errors=\"ignore\")\n",
    "    text = ' '.join(f.readlines())   # Read in text.\n",
    "    # Find triple-linebreaks.\n",
    "    chunks = [ind.start() for ind in re.finditer('\\n\\s*\\n\\s*\\n', text)]\n",
    "    # Remove chunks as before.\n",
    "    text = text[:chunks[-1]]\n",
    "    text = text[chunks[0]:]\n",
    "    # Preprocess linebreaks, tabs, and extra spaces.\n",
    "    text = re.sub(r\"\\\\n|\\\\t\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    df.at[i, \"full_text\"] = text   # Save full text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7deca3a6-f7fd-4cc3-8338-df51cc3d0061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest Text: 357844\n",
      "Longest Document: Dombey and Son\n",
      "Smallest Text: 57\n",
      "Shortest Document: Palimpsest\n"
     ]
    }
   ],
   "source": [
    "# Find longest and shortest texts as above.\n",
    "min_text = 999999999\n",
    "max_text = 0\n",
    "for i in df.index:\n",
    "    t_len = len(df.at[i, \"full_text\"].split(\" \"))\n",
    "    if t_len > max_text and t_len:\n",
    "        max_text = t_len\n",
    "        max_ind = i\n",
    "    if t_len < min_text:\n",
    "        min_text = t_len\n",
    "        min_ind = i\n",
    "print(f\"Longest Text: {max_text}\\nLongest Document: {df.at[max_ind, 'title']}\")\n",
    "print(f\"Smallest Text: {min_text}\\nShortest Document: {df.at[min_ind, 'title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a77ca809-fd58-4212-ac24-b35ba5fe1fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest Summary: 5475\n",
      "\tDocument: The Scapegoat\n",
      "Smallest Summary: 43\n",
      "\tDocument: Joseph and His Friend: A Story of Pennsylvania\n"
     ]
    }
   ],
   "source": [
    "# Find longest and shortest summaries, as above.\n",
    "smlst_ts = 999999999\n",
    "bigst_ts = 0\n",
    "for i in df.index:\n",
    "    text = re.sub(r\"\\\\n|\\\\t\", \" \", df.at[i, 'summary'])\n",
    "    t_len = len(text.split(\" \"))\n",
    "    if t_len > bigst_ts:\n",
    "        bigst_ts = t_len\n",
    "        big_ind = i\n",
    "    if t_len < smlst_ts:\n",
    "        smlst_ts = t_len\n",
    "        sml_ind = i\n",
    "print(f\"Longest Summary: {bigst_ts}\\n\\tDocument: {df.at[big_ind, 'title']}\")\n",
    "print(f\"Smallest Summary: {smlst_ts}\\n\\tDocument: {df.at[sml_ind, 'title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad63d80-088e-4620-ae28-dc6d8409c25b",
   "metadata": {},
   "source": [
    "LED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "160b40fa-01e9-4f1b-9c40-381936d64aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code borrowed from https://huggingface.co/pszemraj/led-base-book-summary\n",
    "\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "hf_name = \"pszemraj/led-base-book-summary\"\n",
    "\n",
    "summarizer = pipeline(\n",
    "    \"summarization\",\n",
    "    hf_name,\n",
    "    device=0 if torch.cuda.is_available() else -1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "813c8cc7-1a2b-4a72-a67d-9301cc2d525b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 256, but your input_length is only 5. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You've said a lot of stuff here.\n"
     ]
    }
   ],
   "source": [
    "# More code from https://huggingface.co/pszemraj/led-base-book-summary\n",
    "\n",
    "wall_of_text = \"your words here\"\n",
    "\n",
    "result = summarizer(\n",
    "    wall_of_text,\n",
    "    min_length=8,\n",
    "    max_length=256,\n",
    "    no_repeat_ngram_size=3,\n",
    "    encoder_no_repeat_ngram_size=3,\n",
    "    repetition_penalty=3.5,\n",
    "    num_beams=4,\n",
    "    do_sample=False,\n",
    "    early_stopping=True,\n",
    ")\n",
    "print(result[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9a7c380-eb9c-4af8-b181-31597ca280d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df.at[0, \"full_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e22f383d-964b-4cd6-9301-97fa6c6b4ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Summary: 60/100\n",
      "22/22.0 Iterations Complete\n"
     ]
    }
   ],
   "source": [
    "# Dict to hold results. \n",
    "results = {\"title\":[], \"target\":[], \"pred\":[], \"bleu\":[], \"rouge\":[]}\n",
    "diver = len(df.at[10, \"full_text\"].split(\" \"))/8000   # Sample diver.\n",
    "max_inp = 9500   # Max input size.\n",
    "\n",
    "for j in range(0, 60):   # For each in first 60.\n",
    "    # Check if text is shorter than max input.\n",
    "    if len(df.at[j, \"full_text\"].split(\" \")) < max_inp:\n",
    "        # If within range, summarize.\n",
    "        test_res = summarizer(\n",
    "            df.at[j, \"full_text\"],\n",
    "            min_length=smlst,\n",
    "            max_length=bigst,\n",
    "            no_repeat_ngram_size=3,\n",
    "            encoder_no_repeat_ngram_size=3,\n",
    "            repetition_penalty=3.5,\n",
    "            num_beams=4,\n",
    "            do_sample=False,\n",
    "            early_stopping=True,\n",
    "        )\n",
    "        # Extract summary.\n",
    "        sub_sum = test_res[0][\"summary_text\"]\n",
    "        # Update progress.\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Current Summary: {i+1}/{len(df.index)}\")\n",
    "        \n",
    "    else:   # If outside of range.\n",
    "        sub_sum = \"\"   # Empty string for summary.\n",
    "        diver = len(df.at[j, \"full_text\"].split(\" \"))/max_inp   # Length to divide text by.\n",
    "        max_div = diver//1 + 1   # Number of divisions.\n",
    "    \n",
    "        for i in range(0, int(max_div)):   # For each dividsion.\n",
    "            if i != max_div-1:    # If not last division.\n",
    "                # Select text within range.\n",
    "                new_text = \" \".join(df.at[j, \"full_text\"].split(\" \")[i*max_inp:(i+1)*max_inp])\n",
    "            else:   # If last division.\n",
    "                # Select all remaining text.\n",
    "                new_text = \" \".join(df.at[j, \"full_text\"].split(\" \")[max_inp*(i+1):])\n",
    "            \n",
    "            # Summarize snew_text.\n",
    "            test_res = summarizer(\n",
    "                new_text,\n",
    "                min_length=round(smlst/diver),\n",
    "                max_length=round(bigst/diver),\n",
    "                no_repeat_ngram_size=3,\n",
    "                encoder_no_repeat_ngram_size=3,\n",
    "                repetition_penalty=3.5,\n",
    "                num_beams=4,\n",
    "                do_sample=False,\n",
    "                early_stopping=True,\n",
    "            )\n",
    "            # Add sub-summary to full summary.\n",
    "            sub_sum += test_res[0]['summary_text'] + \" \"\n",
    "            \n",
    "            # Track progress.\n",
    "            clear_output(wait=True)\n",
    "            print(f\"Current Summary: {j+1}/{len(df.index)}\")\n",
    "            print(f\"{i+1}/{max_div} Iterations Complete\")\n",
    "\n",
    "    # Extract target summary.\n",
    "    target = df.at[j, \"summary\"]\n",
    "    full_output = sub_sum.strip()   # Strip extra spaces.\n",
    "    \n",
    "    # Compute metrics.\n",
    "    blue = bleu_scorer.sentence_score(hypothesis=full_output, references=[target])\n",
    "    red = rouge_scorer.get_scores(hyps=full_output, refs=target)\n",
    "    \n",
    "    # Add features to dict.\n",
    "    results[\"title\"].append(df.at[j, \"title\"])\n",
    "    results[\"target\"].append(target)\n",
    "    results[\"pred\"].append(full_output)\n",
    "    results['bleu'].append(blue.score)\n",
    "    results['rouge'].append(red[0][\"rouge-l\"][\"f\"])\n",
    "        \n",
    "# Save results to data frame.\n",
    "test_df = pd.DataFrame(results)\n",
    "# Save df as csv.\n",
    "test_df.to_csv(\"/home/x-mbemus/Desktop/led_test_result3a.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6556c552-dda5-4bd8-8b3c-f04f4cfb8856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Summary: 74/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 2578, but your input_length is only 2. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 1464, but your input_length is only 2. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 326, but your input_length is only 2. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 1470, but your input_length is only 2. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 636, but your input_length is only 2. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 359, but your input_length is only 2. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 806, but your input_length is only 2. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 515, but your input_length is only 2. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 2677, but your input_length is only 2. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 320, but your input_length is only 2. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 331, but your input_length is only 2. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 1747, but your input_length is only 2. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 1593, but your input_length is only 2. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 1652, but your input_length is only 2. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 203, but your input_length is only 2. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 767, but your input_length is only 2. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 1231, but your input_length is only 2. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 1268, but your input_length is only 2. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 271, but your input_length is only 2. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 342, but your input_length is only 2. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 1585, but your input_length is only 2. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 625, but your input_length is only 2. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n"
     ]
    }
   ],
   "source": [
    "# Attempt to repeat above process for 60:100.\n",
    "# Consistently ran into errors. Could only summarize a few here. \n",
    "# Long run time.\n",
    "results = {\"title\":[], \"target\":[], \"pred\":[], \"bleu\":[], \"rouge\":[]}\n",
    "diver = len(df.at[10, \"full_text\"].split(\" \"))/8000\n",
    "max_inp = 9500\n",
    "\n",
    "for j in list(range(60, 84)) + list(range(87, len(df.index))):   # Experiencing errors in this range.\n",
    "    try:\n",
    "        if len(df.at[j, \"full_text\"].split(\" \")) < max_inp:\n",
    "            test_res = summarizer(\n",
    "                df.at[j, \"full_text\"],\n",
    "                min_length=smlst,\n",
    "                max_length=bigst,\n",
    "                no_repeat_ngram_size=3,\n",
    "                encoder_no_repeat_ngram_size=3,\n",
    "                repetition_penalty=3.5,\n",
    "                num_beams=4,\n",
    "                do_sample=False,\n",
    "                early_stopping=True,\n",
    "            )\n",
    "            sub_sum = test_res[0][\"summary_text\"]\n",
    "            clear_output(wait=True)\n",
    "            print(f\"Current Summary: {j+1}/{len(df.index)}\")\n",
    "        \n",
    "        else:\n",
    "            sub_sum = \"\"\n",
    "            diver = len(df.at[j, \"full_text\"].split(\" \"))/max_inp\n",
    "            max_div = diver//1 + 1\n",
    "    \n",
    "            for i in range(0, int(max_div)):\n",
    "                if i != max_div-1: \n",
    "                    new_text = \" \".join(df.at[j, \"full_text\"].split(\" \")[i*max_inp:(i+1)*max_inp])\n",
    "                else:\n",
    "                    new_text = \" \".join(df.at[j, \"full_text\"].split(\" \")[max_inp*(i+1):])\n",
    "        \n",
    "                test_res = summarizer(\n",
    "                    new_text,\n",
    "                    min_length=round(smlst/diver),\n",
    "                    max_length=round(bigst/diver),\n",
    "                    no_repeat_ngram_size=3,\n",
    "                    encoder_no_repeat_ngram_size=3,\n",
    "                    repetition_penalty=3.5,\n",
    "                    num_beams=4,\n",
    "                    do_sample=False,\n",
    "                    early_stopping=True,\n",
    "                )\n",
    "        target = df.at[j, \"summary\"]\n",
    "        full_output = sub_sum.strip()\n",
    "        blue = bleu_scorer.sentence_score(hypothesis=full_output, references=[target])\n",
    "        red = rouge_scorer.get_scores(hyps=full_output, refs=target)\n",
    "        results['bleu'].append(blue.score)\n",
    "        results['rouge'].append(red[0][\"rouge-l\"][\"f\"])\n",
    "        results[\"title\"].append(df.at[j, \"title\"])\n",
    "        results[\"target\"].append(target)\n",
    "        results[\"pred\"].append(full_output)\n",
    "        \n",
    "    except:\n",
    "        results['bleu'].append(0)\n",
    "        results['rouge'].append(0)\n",
    "        results[\"title\"].append(df.at[j,\"title\"])\n",
    "        results[\"target\"].append(df.at[j,\"summary\"])\n",
    "        results['pred'].append(\"\")\n",
    "    \n",
    "        \n",
    "test_df = pd.DataFrame(results)\n",
    "test_df.to_csv(\"/home/x-mbemus/Desktop/led_test_result3b.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c720dbd-35df-41e1-82c3-f913e172b503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 Summaries takes about 11 min 53 sec. Most summaries < 1:10. All below 1:20.\n",
    "len(df.index)\n",
    "# Should take about 3 and a half hours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6781979e-ae2a-4ac9-b630-895f8db3cb82",
   "metadata": {},
   "source": [
    "FalconsAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcecc679-207c-4211-bb18-e8a4fc99afbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (851 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face has emerged as a prominent and innovative force in NLP . From its inception to its role in democratizing AI, the company has left an indelible mark on the industry . The name \"Hugging Face\" was chosen to reflect the company's mission of making AI models more accessible and friendly to humans .\n"
     ]
    }
   ],
   "source": [
    "# Sample code from https://huggingface.co/Falconsai/text_summarization\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"Falconsai/text_summarization\")\n",
    "\n",
    "ARTICLE = \"\"\" \n",
    "Hugging Face: Revolutionizing Natural Language Processing\n",
    "Introduction\n",
    "In the rapidly evolving field of Natural Language Processing (NLP), Hugging Face has emerged as a prominent and innovative force. This article will explore the story and significance of Hugging Face, a company that has made remarkable contributions to NLP and AI as a whole. From its inception to its role in democratizing AI, Hugging Face has left an indelible mark on the industry.\n",
    "The Birth of Hugging Face\n",
    "Hugging Face was founded in 2016 by ClÃ©ment Delangue, Julien Chaumond, and Thomas Wolf. The name \"Hugging Face\" was chosen to reflect the company's mission of making AI models more accessible and friendly to humans, much like a comforting hug. Initially, they began as a chatbot company but later shifted their focus to NLP, driven by their belief in the transformative potential of this technology.\n",
    "Transformative Innovations\n",
    "Hugging Face is best known for its open-source contributions, particularly the \"Transformers\" library. This library has become the de facto standard for NLP and enables researchers, developers, and organizations to easily access and utilize state-of-the-art pre-trained language models, such as BERT, GPT-3, and more. These models have countless applications, from chatbots and virtual assistants to language translation and sentiment analysis.\n",
    "Key Contributions:\n",
    "1. **Transformers Library:** The Transformers library provides a unified interface for more than 50 pre-trained models, simplifying the development of NLP applications. It allows users to fine-tune these models for specific tasks, making it accessible to a wider audience.\n",
    "2. **Model Hub:** Hugging Face's Model Hub is a treasure trove of pre-trained models, making it simple for anyone to access, experiment with, and fine-tune models. Researchers and developers around the world can collaborate and share their models through this platform.\n",
    "3. **Hugging Face Transformers Community:** Hugging Face has fostered a vibrant online community where developers, researchers, and AI enthusiasts can share their knowledge, code, and insights. This collaborative spirit has accelerated the growth of NLP.\n",
    "Democratizing AI\n",
    "Hugging Face's most significant impact has been the democratization of AI and NLP. Their commitment to open-source development has made powerful AI models accessible to individuals, startups, and established organizations. This approach contrasts with the traditional proprietary AI model market, which often limits access to those with substantial resources.\n",
    "By providing open-source models and tools, Hugging Face has empowered a diverse array of users to innovate and create their own NLP applications. This shift has fostered inclusivity, allowing a broader range of voices to contribute to AI research and development.\n",
    "Industry Adoption\n",
    "The success and impact of Hugging Face are evident in its widespread adoption. Numerous companies and institutions, from startups to tech giants, leverage Hugging Face's technology for their AI applications. This includes industries as varied as healthcare, finance, and entertainment, showcasing the versatility of NLP and Hugging Face's contributions.\n",
    "Future Directions\n",
    "Hugging Face's journey is far from over. As of my last knowledge update in September 2021, the company was actively pursuing research into ethical AI, bias reduction in models, and more. Given their track record of innovation and commitment to the AI community, it is likely that they will continue to lead in ethical AI development and promote responsible use of NLP technologies.\n",
    "Conclusion\n",
    "Hugging Face's story is one of transformation, collaboration, and empowerment. Their open-source contributions have reshaped the NLP landscape and democratized access to AI. As they continue to push the boundaries of AI research, we can expect Hugging Face to remain at the forefront of innovation, contributing to a more inclusive and ethical AI future. Their journey reminds us that the power of open-source collaboration can lead to groundbreaking advancements in technology and bring AI within the reach of many.\n",
    "\"\"\"\n",
    "print(summarizer(ARTICLE, max_length=230, min_length=30, do_sample=False)[0][\"summary_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b22e2a4-3cc7-4bab-811a-bb7c82999304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Summary: 100/100\n",
      "163/163.0 Iterations Complete\n"
     ]
    }
   ],
   "source": [
    "# Adapt code from above.\n",
    "max_inp = 512   # Maximum input length.\n",
    "# Dict to hold results.\n",
    "results = {\"title\":[], \"target\":[], \"pred\":[], \"bleu\":[], \"rouge\":[]}\n",
    "\n",
    "for j in df.index:   # Iterate through df.\n",
    "    if len(df.at[j, \"full_text\"].split(\" \")) > max_inp:   # If text longer than max_inp,\n",
    "        \n",
    "        sub_sum = \"\"   # Empty string to hold total summary.\n",
    "        diver = len(df.at[j, \"full_text\"].split(\" \"))/max_inp   # Find dividsion length.\n",
    "        max_div = diver//1 + 1   # Count number of divisions.\n",
    "    \n",
    "        for i in range(0, int(max_div)):   # For each subdivision\n",
    "            if i != max_div-1:    # If not last division.\n",
    "                # Pick certain range out of text.\n",
    "                new_text = \" \".join(df.at[j, \"full_text\"].split(\" \")[i*max_inp:(i+1)*max_inp])\n",
    "            else:   # If last divison.\n",
    "                # Take remaining. \n",
    "                new_text = \" \".join(df.at[j, \"full_text\"].split(\" \")[max_inp*(i+1):])\n",
    "        \n",
    "            # Summarize sub-part of text.\n",
    "            test_res = summarizer(new_text, max_length=round(bigst/diver), min_length=round(smlst/diver), do_sample=False)\n",
    "            sub_sum += test_res[0]['summary_text'] + \" \"   # Add to total summary.\n",
    "            \n",
    "            # Track progress.\n",
    "            clear_output(wait=True)\n",
    "            print(f\"Current Summary: {j+1}/{len(df.index)}\")\n",
    "            print(f\"{i+1}/{max_div} Iterations Complete\")\n",
    "    \n",
    "    else:   # If text length fits in summarizer.\n",
    "        # Summarize text.\n",
    "        test_res = summarizer(df.at[j, \"full_text\"], max_length=bigst, min_length=smlst, do_sample=False)\n",
    "        sub_sum = test_res[0]['summary_text']\n",
    "\n",
    "    target = df.at[j, \"summary\"]   # Extract target response.\n",
    "    full_output = sub_sum.strip()   # Remove extra end spaces.\n",
    "    \n",
    "    # Get scores.\n",
    "    blue = bleu_scorer.sentence_score(hypothesis=full_output, references=[target])\n",
    "    red = rouge_scorer.get_scores(hyps=full_output, refs=target)\n",
    "    \n",
    "    # Add to dict.\n",
    "    results[\"title\"].append(df.at[j, \"title\"])\n",
    "    results[\"target\"].append(target)\n",
    "    results[\"pred\"].append(full_output)\n",
    "    results['bleu'].append(blue.score)\n",
    "    results['rouge'].append(red[0][\"rouge-l\"][\"f\"])\n",
    "\n",
    "# Convert dict to df.\n",
    "test_df = pd.DataFrame(results)\n",
    "# Save df. \n",
    "test_df.to_csv(\"/home/x-mbemus/Desktop/falcon_test_result2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5576bc-01cd-4d98-b687-6fa24fed857e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes about 2 min per summary, 167 summaries, 334 minutes or 5 and 1/2 hours ish."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaed5c3-5b99-4753-a3fe-e98ec2cd817b",
   "metadata": {},
   "source": [
    "Pegasus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e68dd56-ebe2-4d76-91fc-eb35fe780ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sentencepiece\n",
    "import sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f78471a7-70d2-418f-a8fc-f0f8a187e46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/x-mbemus/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3982: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
      "\n",
      "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
      "this:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "labels = tokenizer(text_target=tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "California's largest electricity provider has announced it will cut power to more than 300,000 homes and businesses over the next few days.\n"
     ]
    }
   ],
   "source": [
    "# Sample code from https://towardsdatascience.com/how-to-perform-abstractive-summarization-with-pegasus-3dd74e48bafb\n",
    "\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "import torch\n",
    "src_text = [\n",
    "    \"\"\" PG&E stated it scheduled the blacokouts in response to forecasts for high winds amid dry conditions. The aim is to reduce the damage incurred by the potentially hazardous conditions, which could cause fires if an outage were to occur naturally. \"\"\"\n",
    "]\n",
    "\n",
    "model_name = \"google/pegasus-xsum\"\n",
    "torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
    "batch = tokenizer.prepare_seq2seq_batch(src_text, truncation=True, padding=\"longest\", return_tensors=\"pt\").to(torch_device)\n",
    "translated = model.generate(**batch)\n",
    "tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "print(tgt_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c77a071-0d6d-4ad9-8e05-9fe3817638ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 Summaries Complete\n"
     ]
    }
   ],
   "source": [
    "# Dict to hold results.\n",
    "results = {\"title\":[], \"target\":[], \"pred\":[], \"bleu\":[], \"rouge\":[]}\n",
    "\n",
    "for i in df.index:   # For each test observation.\n",
    "    # Tokenize text.\n",
    "    batch = tokenizer.prepare_seq2seq_batch(df.at[i, \"full_text\"], \n",
    "                                            truncation=True, \n",
    "                                            padding=\"longest\", \n",
    "                                            return_tensors=\"pt\").to(torch_device)\n",
    "    translated = model.generate(**batch)   # Generate summary.\n",
    "    mod_out = tokenizer.batch_decode(translated, skip_special_tokens=True)   # Decode summary.\n",
    "    \n",
    "    target = df.at[i, \"summary\"]   # Extract target.\n",
    "    full_output = mod_out[0]   # Extract output.\n",
    "    \n",
    "    # Compute scores.\n",
    "    blue = bleu_scorer.sentence_score(hypothesis=full_output, references=[target])\n",
    "    red = rouge_scorer.get_scores(hyps=full_output, refs=target)\n",
    "    \n",
    "    # Save results.\n",
    "    results[\"title\"].append(df.at[i, \"title\"])\n",
    "    results[\"target\"].append(target)\n",
    "    results[\"pred\"].append(full_output)\n",
    "    results['bleu'].append(blue.score)\n",
    "    results['rouge'].append(red[0][\"rouge-l\"][\"f\"])\n",
    "    \n",
    "    # Track progress. \n",
    "    clear_output(wait=True)\n",
    "    print(f\"{i+1}/{len(df.index)} Summaries Complete\")\n",
    "\n",
    "# Convert dict to df.\n",
    "result_df = pd.DataFrame(results)\n",
    "# Save df. \n",
    "result_df.to_csv(\"/home/x-mbemus/Desktop/pegasus_test_result2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c267b178-5149-4077-ac48-f938c2919c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>bleu</th>\n",
       "      <th>rouge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Evolution</td>\n",
       "      <td>The book follows the evolution of mankind as ...</td>\n",
       "      <td>In our series of letters from British journali...</td>\n",
       "      <td>2.631998e-04</td>\n",
       "      <td>0.048309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cause of Death</td>\n",
       "      <td>New Year's Eve and the final murder scene of ...</td>\n",
       "      <td>In our series of letters from British journali...</td>\n",
       "      <td>2.112223e-01</td>\n",
       "      <td>0.057692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cursed</td>\n",
       "      <td>Various demons have battled Spike since he wa...</td>\n",
       "      <td>In our series of letters from British journali...</td>\n",
       "      <td>3.928301e-01</td>\n",
       "      <td>0.113636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death in Venice</td>\n",
       "      <td>The main character is Gustav von Aschenbach, ...</td>\n",
       "      <td>In our series of letters from British journali...</td>\n",
       "      <td>4.048940e-17</td>\n",
       "      <td>0.020906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Message</td>\n",
       "      <td>Cassie and Tobias are having strange dreams a...</td>\n",
       "      <td>In our series of letters from British journali...</td>\n",
       "      <td>9.757962e-08</td>\n",
       "      <td>0.037453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             title                                             target  \\\n",
       "0        Evolution   The book follows the evolution of mankind as ...   \n",
       "1   Cause of Death   New Year's Eve and the final murder scene of ...   \n",
       "2           Cursed   Various demons have battled Spike since he wa...   \n",
       "3  Death in Venice   The main character is Gustav von Aschenbach, ...   \n",
       "4      The Message   Cassie and Tobias are having strange dreams a...   \n",
       "\n",
       "                                                pred          bleu     rouge  \n",
       "0  In our series of letters from British journali...  2.631998e-04  0.048309  \n",
       "1  In our series of letters from British journali...  2.112223e-01  0.057692  \n",
       "2  In our series of letters from British journali...  3.928301e-01  0.113636  \n",
       "3  In our series of letters from British journali...  4.048940e-17  0.020906  \n",
       "4  In our series of letters from British journali...  9.757962e-08  0.037453  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open test file.\n",
    "pegasus_test = pd.read_csv(\"/home/x-mbemus/Desktop/pegasus_test_result.csv\")\n",
    "pegasus_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9c62188d-8b14-4385-afe7-d6a4851ca327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.063126158880524"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pegasus_test['bleu'].mean()   # Compute mean bleu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3cfba4e9-b2d3-403d-a200-211c573bfed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04204537295642239"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pegasus_test['rouge'].mean()   # Compute mean rouge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f3f47d7-0580-4d47-8d35-3affe981f017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>bleu</th>\n",
       "      <th>rouge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Evolution</td>\n",
       "      <td>The book follows the evolution of mankind as ...</td>\n",
       "      <td>This eBook is for the use of anyone anywhere i...</td>\n",
       "      <td>0.834725</td>\n",
       "      <td>0.128527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cause of Death</td>\n",
       "      <td>New Year's Eve and the final murder scene of ...</td>\n",
       "      <td>Title: Cause of Death Author: Max Tadlock Rele...</td>\n",
       "      <td>0.314718</td>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cursed</td>\n",
       "      <td>Various demons have battled Spike since he wa...</td>\n",
       "      <td>This eBook is for the use of anyone anywhere i...</td>\n",
       "      <td>0.111076</td>\n",
       "      <td>0.043668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death in Venice</td>\n",
       "      <td>The main character is Gustav von Aschenbach, ...</td>\n",
       "      <td>Gustav Aschenbach had left his apartment on th...</td>\n",
       "      <td>1.018421</td>\n",
       "      <td>0.171306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Message</td>\n",
       "      <td>Cassie and Tobias are having strange dreams a...</td>\n",
       "      <td>Honore de Balzac Translated by Ellen Marriage ...</td>\n",
       "      <td>0.547090</td>\n",
       "      <td>0.123119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             title                                             target  \\\n",
       "0        Evolution   The book follows the evolution of mankind as ...   \n",
       "1   Cause of Death   New Year's Eve and the final murder scene of ...   \n",
       "2           Cursed   Various demons have battled Spike since he wa...   \n",
       "3  Death in Venice   The main character is Gustav von Aschenbach, ...   \n",
       "4      The Message   Cassie and Tobias are having strange dreams a...   \n",
       "\n",
       "                                                pred      bleu     rouge  \n",
       "0  This eBook is for the use of anyone anywhere i...  0.834725  0.128527  \n",
       "1  Title: Cause of Death Author: Max Tadlock Rele...  0.314718  0.057143  \n",
       "2  This eBook is for the use of anyone anywhere i...  0.111076  0.043668  \n",
       "3  Gustav Aschenbach had left his apartment on th...  1.018421  0.171306  \n",
       "4  Honore de Balzac Translated by Ellen Marriage ...  0.547090  0.123119  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open falcon test results.\n",
    "falcon_test = pd.read_csv(\"/home/x-mbemus/Desktop/falcon_test_result2.csv\")\n",
    "falcon_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "885740ea-30c5-44ca-9b0a-bb2c7016662f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1117372780978352"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falcon_test['bleu'].mean()   # Compute mean BLEU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "387db70b-de8d-4984-999a-b3cd5ced6ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1242950205464541"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falcon_test['rouge'].mean()   # Compute mean ROUGE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f33f7de-a1ee-408a-b1b4-216866c54cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (Anaconda 2021.05)",
   "language": "python",
   "name": "anaconda-2021.05-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
